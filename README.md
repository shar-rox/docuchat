# ğŸ¤– DocuChat - Intelligent Document Q&A System

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

> Ask questions about your documents and get accurate, cited answers using RAG (Retrieval-Augmented Generation) and LLMs

## ğŸŒŸ Features

- ğŸ“„ **Multi-document support**: Upload and query multiple PDFs simultaneously
- ğŸ” **Semantic search**: Find relevant context using state-of-the-art vector embeddings
- ğŸ¤– **AI-powered answers**: Generate accurate responses with citations
- ğŸ“Œ **Source citations**: Every answer includes document references with page numbers
- âš¡ **Fast retrieval**: Efficient vector search with ChromaDB
- ğŸ’¬ **Conversation mode**: Ask follow-up questions naturally

## ğŸ—ï¸ Architecture

```
PDF Documents â†’ Document Processor â†’ Chunks
                                       â†“
User Query â†’ Embeddings â†â†’ Vector Store (ChromaDB)
                â†“
          Retriever (Top-K chunks)
                â†“
            LLM + RAG â†’ Answer with Citations
```

## ğŸš€ Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/shar-rox/docuchat.git
cd docuchat

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Set up environment variables
cp .env.example .env
# Edit .env and add your API keys
```

### Usage

```bash
# Process documents
python -m src.cli process --input data/sample_docs/

# Ask questions
python -m src.cli query "What are the main findings in the research paper?"

# Interactive mode
python -m src.cli chat
```

## ğŸ“Š How It Works

1. **Document Ingestion**: PDFs are extracted and split into semantic chunks (500-1000 tokens)
2. **Embedding Generation**: Text chunks are converted to dense vector representations
3. **Vector Storage**: Embeddings are stored in ChromaDB for efficient similarity search
4. **Query Processing**: User questions are embedded using the same model
5. **Context Retrieval**: Top-k most relevant chunks are retrieved via cosine similarity
6. **Answer Generation**: LLM generates contextual answers from retrieved chunks
7. **Citation**: Sources are displayed with document names and page numbers

## ğŸ› ï¸ Tech Stack

- **Embeddings**: Sentence-Transformers (all-MiniLM-L6-v2)
- **Vector Database**: ChromaDB
- **LLM**: OpenAI GPT-4 / Anthropic Claude (configurable)
- **Framework**: LangChain
- **PDF Processing**: PyMuPDF
- **CLI**: Rich (beautiful terminal output)

## ğŸ“ˆ Project Status

- [x] Day 1: Project setup & document processing
- [ ] Day 2: Vector embeddings & ChromaDB integration
- [ ] Day 3: Retrieval system implementation
- [ ] Day 4: LLM integration & RAG pipeline
- [ ] Day 5: CLI interface & UX
- [ ] Day 6: Testing & documentation
- [ ] Day 7: Docker & deployment

## ğŸ§ª Testing

```bash
# Run all tests
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=src --cov-report=html
```

## ğŸ“ Project Structure

```
docuchat/
â”œâ”€â”€ src/                    # Source code
â”‚   â”œâ”€â”€ document_processor.py
â”‚   â”œâ”€â”€ embeddings.py
â”‚   â”œâ”€â”€ vector_store.py
â”‚   â”œâ”€â”€ retriever.py
â”‚   â”œâ”€â”€ llm_interface.py
â”‚   â”œâ”€â”€ rag_pipeline.py
â”‚   â””â”€â”€ cli.py
â”œâ”€â”€ tests/                  # Test suite
â”œâ”€â”€ data/                   # Sample documents
â”œâ”€â”€ config/                 # Configuration files
â”œâ”€â”€ docs/                   # Documentation
â””â”€â”€ notebooks/              # Jupyter notebooks
```

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- Inspired by modern RAG architectures used in production AI systems
- Built with open-source tools and libraries

---

**Note**: This is a portfolio project demonstrating practical AI/ML skills including NLP, vector search, and LLM integration.
